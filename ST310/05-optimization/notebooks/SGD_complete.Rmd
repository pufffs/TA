---
title: "Stochastic gradient descent"
author: "LSE ST310"
output: html_document
---

```{r setup, message = FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
theme_set(theme_minimal(base_size = 16))
```

### Simulate high-dimensional data

Generate data from a high-dimensional model. After your implementation is finished, you can come back here to experiment and see how the algorithm's performance depends on these values. (One interesting experiment: reduce `lambda` in `rpois` to have a sparser `beta` and see how the results change).

```{r}
set.seed(1) # comment/uncomment/change this
n <- 100
p <- 400
X <- matrix(rnorm(n*p), nrow = n)
beta <- rpois(p, lambda = 1.5)
SGD_starting_beta <- rnorm(p) # generate once
#beta <- sample(c(-1, 0, 0, 1), p, replace = TRUE)
sigma <- 2
y <- X %*% beta + rnorm(n, sd = sigma)
# sparsity level
sum(beta != 0)
```

**Question**: Can we fit OLS to estimate beta? Why or why not?

**Answer**: No. Since there are more predictors than observations, i.e. $p > n$, we cannot fit OLS. (The matrix $X^TX$ is not invertible)

### Implement stochastic gradient descent

#### Helper functions

```{r}
# Loss function
least_squares_loss <- function(x, y, beta) {
  residuals <- y - x %*% beta
  sum(residuals^2)
}
```


```{r}
# Gradient of the loss function
least_squares_gradient <- function(x, y, beta) {
  residuals <- y - x %*% beta
  -2 * t(x) %*% residuals
}
```

#### Mini-batch example

Computing gradient on a subset of the sample:

```{r}
batch_size <- 10
batch_indices <- sample(1:nrow(X), batch_size)
X_batch <- X[batch_indices, , drop = FALSE]
y_batch <- y[batch_indices]
gradient_batch <- least_squares_gradient(X_batch, y_batch, SGD_starting_beta)
dim(X_batch)
length(y_batch)
dim(gradient_batch)
```

#### SGD: main loop

Modify the code below to complete your implementation.

In this implementation, normalize the gradient to make it a unit vector before taking a step. Recall that if `v` is vector, then `u <- v / sqrt(sum(v^2))` is a unit vector in the direction of `v`. (Optional: for numerical stability you could also add a small positive number in the denominator like `1e-8`).

```{r}
epochs <- 40 # decrease for early stopping?
batch_size <- 8 # for batch SGD
gamma <- 0.9
beta_hat <- SGD_starting_beta # generated once above
#beta_hat <- rnorm(p) # random start
num_batches <- ceiling(n/batch_size)
steps <- epochs * num_batches
SGD_path <- data.frame(step = 1:steps,
                       epoch = numeric(steps),
                       gamma = numeric(steps),
                       loss = numeric(steps),
                       MSE = numeric(steps),
                       beta_hat_norm = numeric(steps),
                       gradient_norm = numeric(steps))
start_time <- Sys.time()
step <- 1
for (epoch in 1:epochs) {
  # Pass over sample in a random order each time
  shuffled_indices <- sample(1:n, n, replace = TRUE)
  
  for (batch in 1:num_batches) {
    batch_start <- 1 + batch_size * (batch - 1)
    batch_end <- min(batch_size * batch, nrow(X))
    batch_indices <- shuffled_indices[batch_start:batch_end]
   # Mini-batch
    X_batch <- X[batch_indices, , drop = FALSE]
    y_batch <- y[batch_indices]
    # Update beta_hat
   gradient_batch <- least_squares_gradient(X_batch, y_batch, beta_hat)
   gradient_norm <- sqrt(sum(gradient_batch^2))
   beta_hat <- beta_hat - gamma^epoch * gradient_batch / (1e-8 + gradient_norm)
   LS_loss <- least_squares_loss(X, y, beta_hat)

  # Store algorithm path information
  SGD_path[step, ] <- c(step,
                        epoch,
                        gamma^epoch,
                        LS_loss,
                        mean((beta_hat - beta)^2),
                        sqrt(sum(beta_hat^2)),
                        gradient_norm)
  step <- step + 1
  }
}

print(Sys.time() - start_time)
```

## Plots by **epoch**

(Averaged over all batches in that epoch)

Note: the `loss` is plotted on a logarithmic scale so that large initial changes don't obscure later variation.

```{r echo = FALSE, fig.align='center'}
SGD_epoch <- SGD_path |>
  select(-step) |>
  group_by(epoch) |>
  summarize(across(where(is.numeric), mean))
SGD_epoch |>
  ggplot(aes(epoch, gamma)) + geom_point() +
  ylab("gamma^epoch")
SGD_epoch |>
  ggplot(aes(epoch, loss)) + geom_point() +
  ylab("Loss") + scale_y_log10()
SGD_epoch |>
  ggplot(aes(epoch, MSE)) + geom_point() +
  ylab("MSE(beta_hat)")
SGD_epoch |>
  ggplot(aes(epoch, beta_hat_norm)) + geom_point() +
  ylab("norm(beta_hat)")
SGD_epoch |>
  ggplot(aes(epoch, gradient_norm)) + geom_point() +
  ylab("norm(gradient)")
```

**Question**: Does the MSE of beta_hat level off? After roughly how many epochs? Is this happening because `gamma` decreased too fast?

**Answer**: Yes, in this example after roughly 20 epochs, and no because the `gamma` value is still over 0.1 (has not yet become numerically very close to zero).

## Plots by **mini-batch**

```{r echo = FALSE, fig.align='center'}
SGD_path |>
  ggplot(aes(step, gamma)) + geom_point() +
  ylab("gamma^epoch")
SGD_path |>
  ggplot(aes(step, loss)) + geom_point() +
  ylab("Loss") + scale_y_log10()
SGD_path |>
  ggplot(aes(step, MSE)) + geom_point() +
  ylab("MSE(beta_hat)")
SGD_path |>
  ggplot(aes(step, beta_hat_norm)) + geom_point() +
  ylab("norm(beta_hat)")
SGD_path |>
  ggplot(aes(step, gradient_norm)) + geom_point() +
  ylab("norm(gradient)")
```

## Squared errors

Has the algorithm pulled more of the squared errors closer to zero compared to the (random) initial starting point?

```{r echo=FALSE}
data.frame(
  coordinate = c(1:p, 1:p),
  estimate = c(rep("initial", p), rep("final", p)),
  error = c(beta - SGD_starting_beta, beta - beta_hat)
) |>
  ggplot(aes(error^2, fill = estimate)) +
  geom_density(alpha = .7) +
  scale_fill_viridis_d()
```

Compute the (Euclidean) distances between the following points:

```{r}
# From algorithm starting point to end point
sqrt(sum((beta_hat - SGD_starting_beta)^2))
# From starting point to true beta
sqrt(sum((beta - SGD_starting_beta)^2))
# From end point to true beta
sqrt(sum((beta - beta_hat)^2))
```

**Question**: Does SGD do better than a random guess (the starting point) at estimating the true coefficients?

**Answer**: Yes, after taking some steps the algorithm has reduced the MSE of estimating the true beta.


```{r}
batch_size = 32

sigmoid <- function(z) {
  1 / (1 + exp(-z))
}

BCE_loss <- function(y_true, y_pred) {
  #TO DO
  -mean(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))
}

logistic_gradient <- function(y_true, y_pred, X){
  #TO DO
  -colMeans( X*(y_true-y_pred) )
}

sgd_logistic_regression <- function(train_data, lr = 0.01, epochs = 100) {
  X <- as.matrix(train_data[, c("Feature1", "Feature2")])
  y <- train_data$Class
  
  # Add intercept term
  X <- cbind(Intercept = 1, X)
  
  # Initialize weights
  beta_hat <- rep(0, ncol(X))
  
  n <- nrow(X)
  
  loss_history <- numeric(epochs)
  
  num_batches <- ceiling(n/batch_size)
  
  for (epoch in 1:epochs) {
    shuffled_indices <- sample(1:n, n, replace = TRUE)
    
    for (batch in 1:num_batches) {
    batch_start <- 1 + batch_size * (batch - 1)
    batch_end <- min(batch_size * batch, n)
    batch_indices <- shuffled_indices[batch_start:batch_end]
   # Mini-batch
    X_batch <- X[batch_indices, , drop = FALSE]
    y_batch <- y[batch_indices]
    
    # Update beta_hat
    z_batch <- X_batch %*% beta_hat
    y_pred <- as.vector(sigmoid(z_batch))
    
    gradient_batch <- logistic_gradient(y_batch, y_pred, X_batch)
    #gradient_batch <- -colMeans(X_batch*(y_batch-y_pred))
    gradient_norm <- sqrt(sum(gradient_batch^2))
   
    beta_hat <- beta_hat - lr * gradient_batch / (1e-8 + gradient_norm)
    entropy_loss <- BCE_loss(y_batch, y_pred)
   
  }

    if (epoch %% 10 == 0 || epoch == 1) {
      cat("Epoch:", epoch, "- Loss:", round(entropy_loss, 4), "\n")
    }
  }
  
  return(list(weights = beta_hat, loss_history = loss_history))
}

# Train the model
result <- sgd_logistic_regression(train_data, lr = 0.1, epochs = 100)
final_weights <- result$weights
loss_history <- result$loss_history

# Display final weights
cat("Final Weights:\n")
print(final_weights)
```

### Exercise: Please implement the stochastic gradient descent procedure on logistic regression.
$$
L_{SGD}(\mathbf{\beta}) = -\frac{1}{m} \sum_{i=1}^m \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]
$$
 $$
   \hat{y}_i = \sigma(\beta^T \mathbf{x}_i) = \frac{1}{1 + e^{-\beta^T \mathbf{x}_i}}
$$

$$
\frac{d\sigma(z)}{dz}=\sigma(z)(1-\sigma(z))
$$
Hence 
$$
\frac{\partial \hat y_i}{\partial \beta}=\frac{\partial \sigma(\beta^Tx_i)}{\partial \beta}=\sigma(\beta^Tx_i)(1-\sigma(\beta^Tx_i))x_i=\hat{y}_i(1-\hat{y}_i)x_i
$$
Substitute back to the loss function:
$$
\frac{\partial L_{SGD}(\mathbf{\beta})}{\partial \beta}=-\frac{1}{m}\sum^m_{i=1}\big[ y_i(1-\hat y_i)x_i - (1-y_i)\hat y_ix_i \big]=-\frac{1}{m}\sum^m_{i=1}(y_i-\hat y_i)x_i
$$
##### 1. Data generation
```{r}
set.seed(123) 

n <- 500

# Generate Feature1 and Feature2 for Class 0
feature1_class0 <- rnorm(n, mean = 2, sd = 1)
feature2_class0 <- rnorm(n, mean = 2, sd = 1)

# Generate Feature1 and Feature2 for Class 1
feature1_class1 <- rnorm(n, mean = 4, sd = 1)
feature2_class1 <- rnorm(n, mean = 4, sd = 1)

# Combine into data frames
data_class0 <- data.frame(
  Feature1 = feature1_class0,
  Feature2 = feature2_class0,
  Class = 0
)

data_class1 <- data.frame(
  Feature1 = feature1_class1,
  Feature2 = feature2_class1,
  Class = 1
)

# Combine both classes into one dataset
data <- rbind(data_class0, data_class1)

# Introduce some overlap by adding noise
data$Feature1 <- data$Feature1 + rnorm(nrow(data), mean = 0, sd = 0.5)
data$Feature2 <- data$Feature2 + rnorm(nrow(data), mean = 0, sd = 0.5)

# Shuffle the dataset
data <- data[sample(nrow(data)), ]
ggplot(data, aes(x = Feature1, y = Feature2, color = factor(Class))) +
  geom_point(alpha = 0.7) +
  labs(title = "Simulated Binary Classification Dataset",
       x = "Feature 1",
       y = "Feature 2",
       color = "Class") +
  theme_minimal()

```

##### 2. Train-Test split

```{r}
train_proportion <- 0.8
train_indices <- sample(1:nrow(data), size = train_proportion * nrow(data))

# Create training and testing sets
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
```

##### 3. Model training
```{r}
batch_size = 32

sigmoid <- function(z) {
  1 / (1 + exp(-z))
}

BCE_loss <- function(y_true, y_pred) {
  #TO DO
}

logistic_gradient <- function(y_true, y_pred, X){
  #TO DO
}

sgd_logistic_regression <- function(train_data, lr = 0.01, epochs = 100) {
  X <- as.matrix(train_data[, c("Feature1", "Feature2")])
  y <- train_data$Class
  
  # Add intercept term
  X <- cbind(Intercept = 1, X)
  
  # Initialize weights
  beta_hat <- rep(0, ncol(X))
  
  n <- nrow(X)
  
  loss_history <- numeric(epochs)
  
  num_batches <- ceiling(n/batch_size)
  
  for (epoch in 1:epochs) {
    shuffled_indices <- sample(1:n, n, replace = TRUE)
    
    for (batch in 1:num_batches) {
    #TO DO
      
  }

    if (epoch %% 10 == 0 || epoch == 1) {
      cat("Epoch:", epoch, "- Loss:", round(entropy_loss, 4), "\n")
    }
  }
  
  return(list(weights = beta_hat, loss_history = loss_history))
}

# Train the model
result <- sgd_logistic_regression(train_data, lr = 0.1, epochs = 100)
final_weights <- result$weights
loss_history <- result$loss_history

# Display final weights
cat("Final Weights:\n")
print(final_weights)
```

##### 4. Evaluation on test set

The decision boundry is the hyperplane where
$$
\beta^Tx = 0 \rightarrow~~\beta_0+\beta_1x_1+\beta_2x_2=0\rightarrow ~~x_2=-\frac{\beta_0+\beta_1x_1}{\beta_2}
$$
Hence, for two-dimensional data, we can sample a sequence of x1 and obtain x2 according to the above decision boundry. This will give us a line that seperates the data.

```{r}
X_test <- as.matrix(test_data[, c("Feature1", "Feature2")])
y_test <- test_data$Class

# Add intercept term
X_test <- cbind(Intercept = 1, X_test)

# Compute predictions
z_test <- X_test %*% final_weights
y_hat_test <- sigmoid(z_test)
predictions_test <- ifelse(y_hat_test >= 0.5, 1, 0)

# Calculate accuracy
accuracy_test <- mean(predictions_test == y_test)

beta0 <- final_weights[1]
beta1 <- final_weights[2]
beta2 <- final_weights[3]

# Define decision boundary function
decision_boundary <- function(x1) {
  -(beta0 + beta1 * x1) / beta2
}

x1_vals <- seq(min(train_data$Feature1) - 1, max(train_data$Feature1) + 1, length.out = 100)
x2_vals <- decision_boundary(x1_vals)
ggplot(test_data, aes(x = Feature1, y = Feature2, color = factor(Class))) +
  geom_point(alpha = 0.7) +
  # Add the decision boundary using a separate data frame
  geom_line(data = data.frame(Feature1 = x1_vals, Feature2 = x2_vals), 
            aes(x = Feature1, y = Feature2), 
            color = "black", size = 1) +
  labs(title = "Decision Boundary on Testing Data",
       x = "Feature 1",
       y = "Feature 2",
       color = "Class") +
  theme_minimal()



```

