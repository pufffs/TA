beta_prev1 <- beta_prev2 + 0.1 * grad_prev2 / sqrt(sum(grad_prev2^2)) #some ascending update
grad_prev1 <- numeric_grad(X, Y, beta_prev1)
previous_loss <- neglogL(X, Y, beta_prev2)
next_loss <- neglogL(X, Y, beta_prev1)
steps <- 1
tol <- 1e-5
while (abs(previous_loss - next_loss) > tol) {
# Compute BB step size
grad_diff <- grad_prev1 - grad_prev2
step_BB <- abs(sum((beta_prev1 - beta_prev2) * grad_diff)) / sum(grad_diff^2)
beta_prev2 <- beta_prev1 # for the (n+1)-th step, beta_{n} becomes beta_{n-1}
# Update step
beta_prev1 <- beta_prev1 - step_BB * grad_prev1 # update the newest parameter
# Shift previous steps
grad_prev2 <- grad_prev1
grad_prev1 <- numeric_grad(X, Y, beta_prev1)
previous_loss <- next_loss
next_loss <- neglogL(X, Y, beta_prev1)
# Print beta values and loss for the first 5 steps
if (steps <= 5) {
cat("Step ", steps, ":\n")
cat("Beta_prev2: ", beta_prev2, "\n")
cat("Beta_prev1: ", beta_prev1, "\n")
cat("Loss: ", next_loss, "\n\n")
}
# Print loss every 5 steps, track path, control loop
if (round(steps / 5) == steps / 5) print(previous_loss)
steps <- steps + 1
beta_path[steps, 2] <- next_loss
beta_path[steps, 3:ncol(beta_path)] <- beta_prev1
if (steps > max_steps) break
}
set.seed(1) # comment/uncomment/change this
n <- 100
p <- 400
X <- matrix(rnorm(n*p), nrow = n)
beta <- rpois(p, lambda = 1.5)
SGD_starting_beta <- rnorm(p) # generate once
#beta <- sample(c(-1, 0, 0, 1), p, replace = TRUE)
sigma <- 2
y <- X %*% beta + rnorm(n, sd = sigma)
# sparsity level
sum(beta != 0)
data(iris)
data(iris)
iris <- iris %>%
mutate(Label = ifelse(Species == "setosa", 1, 0)) %>%
select(Label, everything())
View(iris)
library(MASS)
library(dplyr)
# Load the German Credit dataset from MASS package
data("GermanCredit")
# Convert the response variable to binary (1 for "Good", 0 for "Bad")
df <- GermanCredit
ibrary(caret)
library(caret)
install.packages("caret")
library(caret)
library(dplyr)
# Load the German Credit dataset from caret
data("GermanCredit", package = "caret")
library(caret)
library(dplyr)
# Load the German Credit dataset from caret
data("GermanCredit", package = "caret")
df <- GermanCredit
View(df)
# Load required libraries
library(MASS)
library(dplyr)
# Load the German Credit dataset from MASS package
data("GermanCredit")
# Convert the response variable to binary (1 for "Good", 0 for "Bad")
df <- GermanCredit
df$Class <- ifelse(df$Class == "Good", 1, 0)
# Select a subset of numeric columns for simplicity
# Using variables with numeric or integer types only for easier implementation
df <- df %>% select(Class, Duration, Amount, Age)
# Load required libraries
# Load required libraries
library(caret)
library(dplyr)
# Load the German Credit dataset from caret
data("GermanCredit", package = "caret")
# Convert the response variable to binary (1 for "Good", 0 for "Bad")
df <- GermanCredit
df$Class <- ifelse(df$Class == "Good", 1, 0)
# Select a subset of numeric columns for simplicity
df <- df %>% select(Class, Duration, Amount, Age)
library(ggplot2)
library(ggplot2)
set.seed(123)  # For reproducibility
# Number of samples per class
n <- 100
# Generate feature1 for Class 0
feature1_class0 <- rnorm(n, mean = 2, sd = 1)
# Generate feature2 for Class 0
feature2_class0 <- rnorm(n, mean = 2, sd = 1)
# Generate feature1 for Class 1
feature1_class1 <- rnorm(n, mean = 4, sd = 1)
# Generate feature2 for Class 1
feature2_class1 <- rnorm(n, mean = 4, sd = 1)
# Combine into a data frame
data_class0 <- data.frame(
Feature1 = feature1_class0,
Feature2 = feature2_class0,
Class = 0
)
data_class1 <- data.frame(
Feature1 = feature1_class1,
Feature2 = feature2_class1,
Class = 1
)
# Combine both classes
data <- rbind(data_class0, data_class1)
# Shuffle the data
data <- data[sample(nrow(data)), ]
# View the first few row
ggplot(data, aes(x = Feature1, y = Feature2, color = factor(Class))) +
geom_point(alpha = 0.7) +
labs(title = "Simulated Binary Classification Dataset",
x = "Feature 1",
y = "Feature 2",
color = "Class") +
theme_minimal()
set.seed(123)  # For reproducibility
# Number of samples per class
n <- 100
# Generate feature1 for Class 0
feature1_class0 <- rnorm(n, mean = 2, sd = 1)
# Generate feature2 for Class 0
feature2_class0 <- rnorm(n, mean = 2, sd = 1)
# Generate feature1 for Class 1
feature1_class1 <- rnorm(n, mean = 4, sd = 1)
# Generate feature2 for Class 1
feature2_class1 <- rnorm(n, mean = 4, sd = 1)
# Combine into a data frame
data_class0 <- data.frame(
Feature1 = feature1_class0,
Feature2 = feature2_class0,
Class = 0
)
data_class1 <- data.frame(
Feature1 = feature1_class1,
Feature2 = feature2_class1,
Class = 1
)
# Combine both classes
data <- rbind(data_class0, data_class1)
# Shuffle the data
data <- data[sample(nrow(data)), ]
ggplot(data, aes(x = Feature1, y = Feature2, color = factor(Class))) +
geom_point(alpha = 0.7) +
labs(title = "Simulated Binary Classification Dataset",
x = "Feature 1",
y = "Feature 2",
color = "Class") +
theme_minimal()
set.seed(123)  # For reproducibility
# Proportion of training data
train_proportion <- 0.8
train_indices <- sample(1:nrow(data), size = train_proportion * nrow(data))
# Create training and testing sets
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Check the distribution
table(train_data$Class)
table(test_data$Class)
set.seed(123)  # For reproducibility
# Proportion of training data
train_proportion <- 0.8
train_indices <- sample(1:nrow(data), size = train_proportion * nrow(data))
# Create training and testing sets
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
sigmoid <- function(z) {
1 / (1 + exp(-z))
}
compute_loss <- function(y_true, y_pred) {
# Adding a small value to prevent log(0)
epsilon <- 1e-15
y_pred <- pmin(pmax(y_pred, epsilon), 1 - epsilon)
-mean(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))
}
sigmoid <- function(z) {
1 / (1 + exp(-z))
}
compute_loss <- function(y_true, y_pred) {
# Adding a small value to prevent log(0)
epsilon <- 1e-15
y_pred <- pmin(pmax(y_pred, epsilon), 1 - epsilon)
-mean(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))
sgd_logistic_regression <- function(train_data, learning_rate = 0.01, epochs = 100) {
X <- as.matrix(train_data[, c("Feature1", "Feature2")])
y <- train_data$Class
# Add intercept term
X <- cbind(Intercept = 1, X)
# Initialize weights
weights <- rep(0, ncol(X))
m <- nrow(X)
loss_history <- numeric(epochs)
for (epoch in 1:epochs) {
indices <- sample(1:m)
X_shuffled <- X[indices, ]
y_shuffled <- y[indices]
for (i in 1:m) {
xi <- X_shuffled[i, ]
yi <- y_shuffled[i]
z <- sum(weights * xi)
y_hat <- sigmoid(z)
gradient <- (y_hat - yi) * xi
weights <- weights - learning_rate * gradient
}
z_all <- X %*% weights
y_hat_all <- sigmoid(z_all)
loss <- compute_loss(y, y_hat_all)
loss_history[epoch] <- loss
if (epoch %% 10 == 0 || epoch == 1) {
cat("Epoch:", epoch, "- Loss:", round(loss, 4), "\n")
}
}
return(list(weights = weights, loss_history = loss_history))
}
sigmoid <- function(z) {
1 / (1 + exp(-z))
}
compute_loss <- function(y_true, y_pred) {
# Adding a small value to prevent log(0)
epsilon <- 1e-15
y_pred <- pmin(pmax(y_pred, epsilon), 1 - epsilon)
-mean(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))
}
sgd_logistic_regression <- function(train_data, learning_rate = 0.01, epochs = 100) {
X <- as.matrix(train_data[, c("Feature1", "Feature2")])
y <- train_data$Class
# Add intercept term
X <- cbind(Intercept = 1, X)
# Initialize weights
weights <- rep(0, ncol(X))
m <- nrow(X)
loss_history <- numeric(epochs)
for (epoch in 1:epochs) {
indices <- sample(1:m)
X_shuffled <- X[indices, ]
y_shuffled <- y[indices]
for (i in 1:m) {
xi <- X_shuffled[i, ]
yi <- y_shuffled[i]
z <- sum(weights * xi)
y_hat <- sigmoid(z)
gradient <- (y_hat - yi) * xi
weights <- weights - learning_rate * gradient
}
z_all <- X %*% weights
y_hat_all <- sigmoid(z_all)
loss <- compute_loss(y, y_hat_all)
loss_history[epoch] <- loss
if (epoch %% 10 == 0 || epoch == 1) {
cat("Epoch:", epoch, "- Loss:", round(loss, 4), "\n")
}
}
return(list(weights = weights, loss_history = loss_history))
}
sigmoid <- function(z) {
1 / (1 + exp(-z))
}
compute_loss <- function(y_true, y_pred) {
# Adding a small value to prevent log(0)
epsilon <- 1e-15
y_pred <- pmin(pmax(y_pred, epsilon), 1 - epsilon)
-mean(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))
}
sgd_logistic_regression <- function(train_data, learning_rate = 0.01, epochs = 100) {
X <- as.matrix(train_data[, c("Feature1", "Feature2")])
y <- train_data$Class
# Add intercept term
X <- cbind(Intercept = 1, X)
# Initialize weights
weights <- rep(0, ncol(X))
m <- nrow(X)
loss_history <- numeric(epochs)
for (epoch in 1:epochs) {
indices <- sample(1:m)
X_shuffled <- X[indices, ]
y_shuffled <- y[indices]
for (i in 1:m) {
xi <- X_shuffled[i, ]
yi <- y_shuffled[i]
z <- sum(weights * xi)
y_hat <- sigmoid(z)
gradient <- (y_hat - yi) * xi
weights <- weights - learning_rate * gradient
}
z_all <- X %*% weights
y_hat_all <- sigmoid(z_all)
loss <- compute_loss(y, y_hat_all)
loss_history[epoch] <- loss
if (epoch %% 10 == 0 || epoch == 1) {
cat("Epoch:", epoch, "- Loss:", round(loss, 4), "\n")
}
}
return(list(weights = weights, loss_history = loss_history))
}
# Train the model
result <- sgd_logistic_regression(train_data, learning_rate = 0.1, epochs = 100)
final_weights <- result$weights
loss_history <- result$loss_history
# Display final weights
cat("Final Weights:\n")
print(final_weights)
# Extract weights
w0 <- final_weights[1]
w1 <- final_weights[2]
w2 <- final_weights[3]
# Define decision boundary function
decision_boundary <- function(x1) {
-(w0 + w1 * x1) / w2
}
# Generate a sequence of x1 values
x1_vals <- seq(min(data$Feature1) - 1, max(data$Feature1) + 1, length.out = 100)
x2_vals <- decision_boundary(x1_vals)
# Plot the training data and decision boundary
ggplot(train_data, aes(x = Feature1, y = Feature2, color = factor(Class))) +
geom_point(alpha = 0.7) +
geom_line(aes(x = x1_vals, y = x2_vals), color = "black", size = 1) +
labs(title = "Decision Boundary on Training Data",
x = "Feature 1",
y = "Feature 2",
color = "Class") +
theme_minimal()
# Extract weights
w0 <- final_weights[1]
w1 <- final_weights[2]
w2 <- final_weights[3]
# Define decision boundary function
decision_boundary <- function(x1) {
-(w0 + w1 * x1) / w2
}
# Generate a sequence of x1 values
x1_vals <- seq(min(data$Feature1) - 1, max(data$Feature1) + 1, length.out = 100)
x2_vals <- decision_boundary(x1_vals)
# Plot the training data and decision boundary
ggplot(train_data, aes(x = Feature1, y = Feature2, color = factor(Class))) +
geom_point(alpha = 0.7) +
geom_line(aes(x = x1_vals, y = x2_vals), color = "black", linewidth = 1) +
labs(title = "Decision Boundary on Training Data",
x = "Feature 1",
y = "Feature 2",
color = "Class") +
theme_minimal()
# Extract testing features and labels
X_test <- as.matrix(test_data[, c("Feature1", "Feature2")])
y_test <- test_data$Class
# Add intercept term
X_test <- cbind(Intercept = 1, X_test)
# Compute predictions
z_test <- X_test %*% final_weights
y_hat_test <- sigmoid(z_test)
predictions_test <- ifelse(y_hat_test >= 0.5, 1, 0)
# Calculate accuracy
accuracy_test <- mean(predictions_test == y_test)
cat("Test Set Accuracy:", round(accuracy_test * 100, 2), "%\n")
# Extract testing features and labels
X_test <- as.matrix(test_data[, c("Feature1", "Feature2")])
y_test <- test_data$Class
# Add intercept term
X_test <- cbind(Intercept = 1, X_test)
# Compute predictions
z_test <- X_test %*% final_weights
y_hat_test <- sigmoid(z_test)
predictions_test <- ifelse(y_hat_test >= 0.5, 1, 0)
# Calculate accuracy
accuracy_test <- mean(predictions_test == y_test)
cat("Test Set Accuracy:", round(accuracy_test * 100, 2), "%\n")
# Plot the testing data and decision boundary
ggplot(test_data, aes(x = Feature1, y = Feature2, color = factor(Class))) +
geom_point(alpha = 0.7) +
geom_line(aes(x = x1_vals, y = x2_vals), color = "black", size = 1) +
labs(title = "Decision Boundary on Testing Data",
x = "Feature 1",
y = "Feature 2",
color = "Class") +
theme_minimal()
# Extract testing features and labels
X_test <- as.matrix(test_data[, c("Feature1", "Feature2")])
y_test <- test_data$Class
# Add intercept term
X_test <- cbind(Intercept = 1, X_test)
# Compute predictions
z_test <- X_test %*% final_weights
y_hat_test <- sigmoid(z_test)
predictions_test <- ifelse(y_hat_test >= 0.5, 1, 0)
# Calculate accuracy
accuracy_test <- mean(predictions_test == y_test)
cat("Test Set Accuracy:", round(accuracy_test * 100, 2), "%\n")
# Plot the testing data and decision boundary
# Plot the testing data and decision boundary
ggplot(test_data, aes(x = Feature1, y = Feature2, color = factor(Class))) +
geom_point(alpha = 0.7) +
# Add the decision boundary using a separate data frame
geom_line(data = data.frame(Feature1 = x1_vals, Feature2 = x2_vals),
aes(x = Feature1, y = Feature2),
color = "black", size = 1) +
labs(title = "Decision Boundary on Testing Data",
x = "Feature 1",
y = "Feature 2",
color = "Class") +
theme_minimal()
set.seed(123)
n <- 500
feature1_class0 <- rnorm(n, mean = 2, sd = 1)
feature2_class0 <- rnorm(n, mean = 2, sd = 1)
feature1_class1 <- rnorm(n, mean = 4, sd = 1)
feature2_class1 <- rnorm(n, mean = 4, sd = 1)
data_class0 <- data.frame(
Feature1 = feature1_class0,
Feature2 = feature2_class0,
Class = 0
)
data_class1 <- data.frame(
Feature1 = feature1_class1,
Feature2 = feature2_class1,
Class = 1
)
data <- rbind(data_class0, data_class1)
data <- data[sample(nrow(data)), ]
ggplot(data, aes(x = Feature1, y = Feature2, color = factor(Class))) +
geom_point(alpha = 0.7) +
labs(title = "Simulated Binary Classification Dataset",
x = "Feature 1",
y = "Feature 2",
color = "Class") +
theme_minimal()
set.seed(123)
train_proportion <- 0.8
train_indices <- sample(1:nrow(data), size = train_proportion * nrow(data))
# Create training and testing sets
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
sigmoid <- function(z) {
1 / (1 + exp(-z))
}
compute_loss <- function(y_true, y_pred) {
# Adding a small value to prevent log(0)
epsilon <- 1e-15
y_pred <- pmin(pmax(y_pred, epsilon), 1 - epsilon)
-mean(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))
}
sgd_logistic_regression <- function(train_data, learning_rate = 0.01, epochs = 100) {
X <- as.matrix(train_data[, c("Feature1", "Feature2")])
y <- train_data$Class
# Add intercept term
X <- cbind(Intercept = 1, X)
# Initialize weights
weights <- rep(0, ncol(X))
m <- nrow(X)
loss_history <- numeric(epochs)
for (epoch in 1:epochs) {
indices <- sample(1:m)
X_shuffled <- X[indices, ]
y_shuffled <- y[indices]
for (i in 1:m) {
xi <- X_shuffled[i, ]
yi <- y_shuffled[i]
z <- sum(weights * xi)
y_hat <- sigmoid(z)
gradient <- (y_hat - yi) * xi
weights <- weights - learning_rate * gradient
}
z_all <- X %*% weights
y_hat_all <- sigmoid(z_all)
loss <- compute_loss(y, y_hat_all)
loss_history[epoch] <- loss
if (epoch %% 10 == 0 || epoch == 1) {
cat("Epoch:", epoch, "- Loss:", round(loss, 4), "\n")
}
}
return(list(weights = weights, loss_history = loss_history))
}
# Train the model
result <- sgd_logistic_regression(train_data, learning_rate = 0.1, epochs = 100)
final_weights <- result$weights
loss_history <- result$loss_history
# Display final weights
cat("Final Weights:\n")
print(final_weights)
# Extract testing features and labels
X_test <- as.matrix(test_data[, c("Feature1", "Feature2")])
y_test <- test_data$Class
# Add intercept term
X_test <- cbind(Intercept = 1, X_test)
# Compute predictions
z_test <- X_test %*% final_weights
y_hat_test <- sigmoid(z_test)
predictions_test <- ifelse(y_hat_test >= 0.5, 1, 0)
# Calculate accuracy
accuracy_test <- mean(predictions_test == y_test)
cat("Test Set Accuracy:", round(accuracy_test * 100, 2), "%\n")
# Plot the testing data and decision boundary
# Plot the testing data and decision boundary
ggplot(test_data, aes(x = Feature1, y = Feature2, color = factor(Class))) +
geom_point(alpha = 0.7) +
# Add the decision boundary using a separate data frame
geom_line(data = data.frame(Feature1 = x1_vals, Feature2 = x2_vals),
aes(x = Feature1, y = Feature2),
color = "black", size = 1) +
labs(title = "Decision Boundary on Testing Data",
x = "Feature 1",
y = "Feature 2",
color = "Class") +
theme_minimal()
