knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(broom)
library(selectiveInference)
library(glmnet)   # For Lasso regression
library(ggplot2)  # For visualization
library(dplyr)    # For data manipulation
set.seed(123)     # Set seed for reproducibility
# Step 1: Simulate Dataset
n <- 100
p <- 10
X <- matrix(rnorm(n * p), nrow = n, ncol = p)  # Randomly generated features
beta <- c(3, 2, 0, 0, 0, -1, 0, 0, 1, 0)       # Coefficients with some set to zero
y <- X %*% beta + rnorm(n)                      # Simulated response with noise
dataset <- data.frame(X, y)
# Step 2: Fit Lasso Model with Varying Lambda
# We use a wide range of lambda values to observe shrinkage
lambda_values <- 10^seq(3, -2, length.out = 100)
lasso_model <- glmnet(X, y, alpha = 1, lambda = lambda_values)
# Step 3: Extract Coefficients for Plotting
lasso_coefs <- as.data.frame(as.matrix(coef(lasso_model)))
lasso_coefs$lambda <- lambda_values
library(glmnet)   # For Lasso regression
library(ggplot2)  # For visualization
library(dplyr)    # For data manipulation
set.seed(123)     # Set seed for reproducibility
# Step 1: Simulate Dataset
n <- 100
p <- 10
X <- matrix(rnorm(n * p), nrow = n, ncol = p)  # Randomly generated features
beta <- c(3, 2, 0, 0, 0, -1, 0, 0, 1, 0)       # Coefficients with some set to zero
y <- X %*% beta + rnorm(n)                      # Simulated response with noise
dataset <- data.frame(X, y)
# Step 2: Fit Lasso Model with Varying Lambda
# We use a wide range of lambda values to observe shrinkage
lambda_values <- 10^seq(3, -2, length.out = 100)
lasso_model <- glmnet(X, y, alpha = 1, lambda = lambda_values)
# Step 3: Extract Coefficients for Plotting
lasso_coefs <- as.data.frame(as.matrix(coef(lasso_model)))
lasso_coefs$lambda <- lambda_values
# Load necessary libraries
library(glmnet)   # For Lasso regression
library(ggplot2)  # For visualization
library(dplyr)    # For data manipulation
set.seed(123)     # Set seed for reproducibility
# Step 1: Simulate Dataset
n <- 100
p <- 10
X <- matrix(rnorm(n * p), nrow = n, ncol = p)  # Randomly generated features
beta <- c(3, 2, 0, 0, 0, -1, 0, 0, 1, 0)       # Coefficients with some set to zero
y <- X %*% beta + rnorm(n)                      # Simulated response with noise
dataset <- data.frame(X, y)
# Step 2: Fit Lasso Model with Varying Lambda
# We use a wide range of lambda values to observe shrinkage
lambda_values <- 10^seq(3, -2, length.out = 100)
lasso_model <- glmnet(X, y, alpha = 1, lambda = lambda_values)
# Step 3: Extract Coefficients for Plotting
lasso_coefs <- as.matrix(coef(lasso_model))
lasso_coefs <- as.data.frame(lasso_coefs[-1, ])  # Remove intercept row
colnames(lasso_coefs) <- paste0("lambda_", seq_along(lambda_values))
lasso_coefs$Feature <- rownames(lasso_coefs)
lasso_coefs_long <- lasso_coefs %>%
pivot_longer(cols = -Feature, names_to = "Lambda", values_to = "Coefficient") %>%
mutate(lambda = as.numeric(gsub("lambda_", "", Lambda))) %>%
mutate(lambda_value = lambda_values[lambda])
# Step 4: Plot Coefficient Paths
ggplot(lasso_coefs_long, aes(x = log(lambda_value), y = Coefficient, color = Feature)) +
geom_line() +
labs(title = "Lasso Coefficient Shrinkage Paths",
x = "Log(Lambda)",
y = "Coefficient Value",
color = "Feature") +
theme_minimal()
# Load necessary libraries
library(glmnet)   # For Lasso regression
library(ggplot2)  # For visualization
library(dplyr)    # For data manipulation
set.seed(123)     # Set seed for reproducibility
# Step 1: Simulate Dataset
n <- 100
p <- 10
X <- matrix(rnorm(n * p), nrow = n, ncol = p)  # Randomly generated features
beta <- c(3, 2, 0, 0, 0, -1, 0, 0, 1, 0)       # Coefficients with some set to zero
y <- X %*% beta + rnorm(n)                      # Simulated response with noise
dataset <- data.frame(X, y)
# Step 2: Fit Lasso Model with Varying Lambda
# We use a wide range of lambda values to observe shrinkage
lambda_values <- 10^seq(3, -2, length.out = 20)
lasso_model <- glmnet(X, y, alpha = 1, lambda = lambda_values)
# Step 3: Extract Coefficients for Plotting
lasso_coefs <- as.matrix(coef(lasso_model))
lasso_coefs <- as.data.frame(lasso_coefs[-1, ])  # Remove intercept row
colnames(lasso_coefs) <- paste0("lambda_", seq_along(lambda_values))
lasso_coefs$Feature <- rownames(lasso_coefs)
lasso_coefs_long <- lasso_coefs %>%
pivot_longer(cols = -Feature, names_to = "Lambda", values_to = "Coefficient") %>%
mutate(lambda = as.numeric(gsub("lambda_", "", Lambda))) %>%
mutate(lambda_value = lambda_values[lambda])
# Step 4: Plot Coefficient Paths
ggplot(lasso_coefs_long, aes(x = log(lambda_value), y = Coefficient, color = Feature)) +
geom_line() +
labs(title = "Lasso Coefficient Shrinkage Paths",
x = "Log(Lambda)",
y = "Coefficient Value",
color = "Feature") +
theme_minimal()
# Load necessary libraries
library(glmnet)   # For Lasso regression
library(ggplot2)  # For visualization
library(dplyr)    # For data manipulation
set.seed(123)     # Set seed for reproducibility
# Step 1: Simulate Dataset
n <- 100
p <- 10
X <- matrix(rnorm(n * p), nrow = n, ncol = p)  # Randomly generated features
beta <- c(3, 2, 0, 0, 0, -1, 0, 0, 1, 0)       # Coefficients with some set to zero
y <- X %*% beta + rnorm(n)                      # Simulated response with noise
dataset <- data.frame(X, y)
# Step 2: Fit Lasso Model with Varying Lambda
# We use a wide range of lambda values to observe shrinkage
lambda_values <- 10^seq(3, -2, length.out = 10)
lasso_model <- glmnet(X, y, alpha = 1, lambda = lambda_values)
# Step 3: Extract Coefficients for Plotting
lasso_coefs <- as.matrix(coef(lasso_model))
lasso_coefs <- as.data.frame(lasso_coefs[-1, ])  # Remove intercept row
colnames(lasso_coefs) <- paste0("lambda_", seq_along(lambda_values))
lasso_coefs$Feature <- rownames(lasso_coefs)
lasso_coefs_long <- lasso_coefs %>%
pivot_longer(cols = -Feature, names_to = "Lambda", values_to = "Coefficient") %>%
mutate(lambda = as.numeric(gsub("lambda_", "", Lambda))) %>%
mutate(lambda_value = lambda_values[lambda])
# Step 4: Plot Coefficient Paths
ggplot(lasso_coefs_long, aes(x = log(lambda_value), y = Coefficient, color = Feature)) +
geom_line() +
labs(title = "Lasso Coefficient Shrinkage Paths",
x = "Log(Lambda)",
y = "Coefficient Value",
color = "Feature") +
theme_minimal()
x <- seq(-1, 1, length.out = 100)
y1 <- 1 - abs(x)
y2 <- -1 + abs(x)
diamond_data <- data.frame(x = c(x, x), y = c(y1, y2))
# Plot the diamond shape
ggplot(diamond_data, aes(x = x, y = y)) +
geom_polygon(fill = "lightblue", color = "blue") +
labs(title = "Diamond Shape of L1 Norm (Lasso Constraint)",
x = expression(beta[1]),
y = expression(beta[2])) +
theme_minimal() +
coord_equal()
library(glmnet)
library(ggplot2)
library(dplyr)
set.seed(123)
# Step 1: Simulate Dataset
n <- 100
p <- 10
X <- matrix(rnorm(n * p), nrow = n, ncol = p)
beta <- c(3, 2, 1, 0, 0)    # Coefficients with some set to zero
y <- X %*% beta + rnorm(n)
library(glmnet)
library(ggplot2)
library(dplyr)
set.seed(123)
# Step 1: Simulate Dataset
n <- 100
p <- 5
X <- matrix(rnorm(n * p), nrow = n, ncol = p)
beta <- c(3, 2, 1, 0, 0)    # Coefficients with some set to zero
y <- X %*% beta + rnorm(n)
dataset <- data.frame(X, y)
# Step 2: Fit Lasso Model with Varying Lambda
lambda_values <- 10^seq(3, -2, length.out = 100)
lasso_model <- glmnet(X, y, alpha = 1, lambda = lambda_values)
# Step 3: Extract Coefficients for Plotting
lasso_coefs <- as.matrix(coef(lasso_model))
lasso_coefs <- as.data.frame(lasso_coefs[-1, ])  # Remove intercept row
colnames(lasso_coefs) <- paste0("lambda_", seq_along(lambda_values))
lasso_coefs$Feature <- rownames(lasso_coefs)
lasso_coefs_long <- lasso_coefs %>%
pivot_longer(cols = -Feature, names_to = "Lambda", values_to = "Coefficient") %>%
mutate(lambda = as.numeric(gsub("lambda_", "", Lambda))) %>%
mutate(lambda_value = lambda_values[lambda])
ggplot(lasso_coefs_long, aes(x = log(lambda_value), y = Coefficient, color = Feature)) +
geom_line() +
labs(title = "Lasso Coefficient Shrinkage Paths",
x = "Log(Lambda)",
y = "Coefficient Value",
color = "Feature") +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(broom)
library(selectiveInference)
install.packages("selectiveInference")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(broom)
library(selectiveInference)
library(glmnet)
library(ggplot2)
library(dplyr)
theme_set(theme_minimal(base_size = 14))
